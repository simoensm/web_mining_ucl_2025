# web_mining_ucl_2025
NLP &amp; DurabilitÃ© : Mesure de la distance sÃ©mantique entre promesse client et reporting corporate.

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Status](https://img.shields.io/badge/Status-Completed-success)
![Course](https://img.shields.io/badge/Course-Web_Mining-orange)

## ğŸ“– Contexte et Objectifs

Ce projet s'inscrit dans le cadre du cours de **Web Mining (MLSMM2153)**. En tant que consultants, notre mission est d'auditer la stratÃ©gie de communication des boutiques en ligne "engagÃ©es".

**Sujet 6 : Ã‰tude de la mise en avant des produits durables.**

L'objectif est de confronter le vocabulaire marketing utilisÃ© sur les fiches produits avec la rÃ©alitÃ© des engagements (ESG/RSE) via une approche "Data-Driven".

### Questions clÃ©s
1. Comment les marques Ã©thiques valorisent-elles sÃ©mantiquement leurs produits ?
2. Existe-t-il une cohÃ©rence entre les catÃ©gories de produits et les promesses durables (Link Analysis) ?
3. Le discours marketing est-il alignÃ© avec les rapports de durabilitÃ© ?

---

## âš™ï¸ Architecture du Projet

Le projet suit un pipeline de donnÃ©es strict en trois Ã©tapes :

### 1. Collecte de DonnÃ©es (Scraping)
* **Cibles :** Sites e-commerce durables et institutionnels.
* **MÃ©thode :** Navigation automatisÃ©e et parsing HTML.
* **StratÃ©gie :** Points d'entrÃ©es ciblÃ©s pour Ã©viter le bruit et garantir un corpus reprÃ©sentatif.
* **Output :** DonnÃ©es structurÃ©es (JSON/CSV).

### 2. Text Mining (NLP)
Transformation du corpus brut en insights sÃ©mantiques.
* **Preprocessing :** Tokenisation, filtrage (Stopwords), Lemmatisation/Stemming.
* **Vectorisation :** TF-IDF / Doc2Vec.
* **Analyses :**
    * *Descriptive :* Nuages de mots, n-grams.
    * *SÃ©mantique :* Analyse de sentiments/tonalitÃ©.
    * *Clustering :* Groupement non supervisÃ© des descriptions produits.

### 3. Link Analysis (Graphes)
ModÃ©lisation des relations entre produits et catÃ©gories.
* **Construction du graphe :** NÅ“uds (Produits/CatÃ©gories) et ArÃªtes (Liens de similaritÃ© ou navigation).
* **MÃ©triques :** Degree Centrality, PageRank, Betweenness.
* **Objectif :** Identifier les produits "ponts" et la structure de l'offre durable.

---

## ğŸ“‚ Structure du RÃ©pertoire

```bash
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # DonnÃ©es brutes issues du scraping (HTML, JSON brut)
â”‚   â””â”€â”€ processed/      # DonnÃ©es nettoyÃ©es et prÃªtes pour l'analyse (CSV, Graphes)
â”œâ”€â”€ notebooks/          # Notebooks Jupyter d'exploration et de visualisation
â”‚   â”œâ”€â”€ 1_scraping.ipynb
â”‚   â”œâ”€â”€ 2_text_mining.ipynb
â”‚   â””â”€â”€ 3_link_analysis.ipynb
â”œâ”€â”€ src/                # Scripts Python rÃ©utilisables
â”‚   â”œâ”€â”€ scraper.py      # Script de collecte
â”‚   â”œâ”€â”€ preprocessing.py # Fonctions de nettoyage NLP
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ reports/            # Graphes gÃ©nÃ©rÃ©s et rapport PDF final
â”œâ”€â”€ requirements.txt    # DÃ©pendances du projet
â””â”€â”€ README.md           # Documentation du projet
